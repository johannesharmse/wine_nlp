{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from glove import Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in dataset 1: 150930\n",
      "Number of entries in dataset 2: 129971\n",
      "\n",
      "Number of duplicate entries across datasets: 48346\n",
      "\n",
      "Number of unique reviews: 169461\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  points\n",
       "0  This tremendous 100% varietal wine hails from ...      96\n",
       "1  Ripe aromas of fig, blackberry and cassis are ...      96\n",
       "2  Mac Watson honors the memory of a wine once ma...      96\n",
       "3  This spent 20 months in 30% new French oak, an...      96\n",
       "4  This is the top wine from La Bégude, named aft...      95"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns to use\n",
    "cols=['description', 'points']\n",
    "\n",
    "# import data\n",
    "reviews_1 = pd.read_csv('../../data/wine-reviews/winemag-data_first150k.csv', index_col=False, usecols=cols)\n",
    "reviews_2 = pd.read_csv('../../data/wine-reviews/winemag-data-130k-v2.csv', index_col=False, usecols=cols)\n",
    "\n",
    "print(\"Number of entries in dataset 1: %s\" %reviews_1.shape[0])\n",
    "print(\"Number of entries in dataset 2: %s\" %reviews_2.shape[0])\n",
    "\n",
    "duplicates = set(reviews_1.description).intersection(set(reviews_2.description))\n",
    "\n",
    "print(\"\\nNumber of duplicate entries across datasets: %s\" % len(duplicates))\n",
    "\n",
    "# concatenate and drop duplicates\n",
    "data = pd.concat([reviews_1,reviews_2])\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"\\nNumber of unique reviews: %s\" % data.shape[0])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_remove = string.punctuation\n",
    "punc_remove = punc_remove.replace('%', '')\n",
    "table = str.maketrans(dict.fromkeys(punc_remove))\n",
    "\n",
    "# lowercase\n",
    "data['description_test'] = data.description_test.str.lower()\n",
    "# remove punctuation\n",
    "data['description_test'] = data.description_test.str.translate(table)\n",
    "# replace percentage sign\n",
    "data['description_test'] = data.description_test.str.replace('%', ' percent')\n",
    "# split words\n",
    "data['description_test'] = data.description_test.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>description_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>96</td>\n",
       "      <td>[this, tremendous, 100, percent, varietal, win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>96</td>\n",
       "      <td>[ripe, aromas, of, fig, blackberry, and, cassi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>96</td>\n",
       "      <td>[mac, watson, honors, the, memory, of, a, wine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>96</td>\n",
       "      <td>[this, spent, 20, months, in, 30, percent, new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>95</td>\n",
       "      <td>[this, is, the, top, wine, from, la, bégude, n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  points  \\\n",
       "0  This tremendous 100% varietal wine hails from ...      96   \n",
       "1  Ripe aromas of fig, blackberry and cassis are ...      96   \n",
       "2  Mac Watson honors the memory of a wine once ma...      96   \n",
       "3  This spent 20 months in 30% new French oak, an...      96   \n",
       "4  This is the top wine from La Bégude, named aft...      95   \n",
       "\n",
       "                                    description_test  \n",
       "0  [this, tremendous, 100, percent, varietal, win...  \n",
       "1  [ripe, aromas, of, fig, blackberry, and, cassi...  \n",
       "2  [mac, watson, honors, the, memory, of, a, wine...  \n",
       "3  [this, spent, 20, months, in, 30, percent, new...  \n",
       "4  [this, is, the, top, wine, from, la, bégude, n...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import Counter\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 58541\n"
     ]
    }
   ],
   "source": [
    "def create_vocabulary(documents):\n",
    "    \"\"\"Unique words and counts\"\"\"\n",
    "    vocabulary = Counter()\n",
    "\n",
    "    for row in documents:\n",
    "        vocabulary.update(row)\n",
    "        \n",
    "    return vocabulary\n",
    "\n",
    "documents = list(data.description_test)\n",
    "vocabulary = create_vocabulary(documents)\n",
    "vocabulary_size = len(vocabulary)\n",
    "\n",
    "print(\"Number of unique words: %s\" % vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_vocabulary(vocabulary, n_words=10000):\n",
    "    \"\"\"Limit vocabulary to highest occurring words and create IDs.\"\"\"\n",
    "    vocabulary_n = list(dict(vocabulary.most_common(n_words - 1)).keys())\n",
    "    vocabulary_n.append('UNK') # placeholder for rare words\n",
    "    \n",
    "    vocabulary_n = dict(zip(vocabulary_n, random.sample(range(0, n_words+1), n_words)))\n",
    "            \n",
    "    return vocabulary_n\n",
    "\n",
    "vocabulary_n = top_vocabulary(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_vocabulary(vocabulary, map_table):\n",
    "    \"\"\"Map vocabulary words to IDs\"\"\"\n",
    "    vocabulary_map_table = dict.fromkeys(vocabulary.keys(), 0)\n",
    "    for word in vocabulary:\n",
    "        if word not in map_table:\n",
    "            vocabulary_map_table[word] = map_table['UNK']\n",
    "        else:\n",
    "            vocabulary_map_table[word] = map_table[word]\n",
    "            \n",
    "    return vocabulary_map_table\n",
    "    \n",
    "vocabulary_map_table = map_vocabulary(vocabulary, vocabulary_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_documents(documents, vocabulary_map_table):\n",
    "    \"\"\"Map documents to integer word IDs\"\"\"\n",
    "    documents_mapped = [[vocabulary_map_table[word] for word in doc] for doc in documents]\n",
    "    \n",
    "    return documents_mapped\n",
    "    \n",
    "documents_mapped = map_documents(documents, vocabulary_map_table)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_index = 0 # keep track of training batches\n",
    "word_index = 0\n",
    "total_num_words = sum([len(doc) for doc in documents_mapped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6868514"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(documents_mapped, batch_size, num_skips, skip_window):\n",
    "    \n",
    "    global review_index\n",
    "    global word_index\n",
    "#     global total_num_word\n",
    "    \n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    \n",
    "    # span considers window on both sides of target word\n",
    "    # we could potentially consider a full sentence or review\n",
    "    # as the context, but keeping it simpler for now\n",
    "    span = 2 * skip_window + 1 \n",
    "    \n",
    "    # init buffer (context and target words)\n",
    "    buffer = collections.deque(maxlen=span)\n",
    "    \n",
    "    # go back to first review if no more reviews left\n",
    "    if review_index >= len(documents_mapped):\n",
    "        review_index = 0\n",
    "    \n",
    "    # make sure there are enough words for skip-gram\n",
    "    # could consider moving to next review instead of recycling words\n",
    "    if word_index + span > len(documents_mapped[word_index]):\n",
    "        word_index = len(documents_mapped[word_index]) - span\n",
    "    \n",
    "    # new skip-gram\n",
    "    buffer.extend(documents_mapped[review_index][word_index:word_index + span])\n",
    "        \n",
    "    for i in range(batch_size // num_skips):\n",
    "        # skip_window is the same as index of target word\n",
    "        context_words = [w for w in range(span) if w != skip_window]\n",
    "        # randomly select context word indices to use\n",
    "        words_to_use = random.sample(context_words, num_skips)\n",
    "        for j, context_word in enumerate(words_to_use):\n",
    "            # target word\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            # context word\n",
    "            labels[i * num_skips + j, 0] = buffer[context_word]\n",
    "        \n",
    "        # add next words / new review for skips\n",
    "        if word_index + span == len(documents_mapped[word_index]):\n",
    "            # next review\n",
    "            word_index = 0\n",
    "            review_index += 1\n",
    "            # start at the beginning if non left\n",
    "            if review_index >= len(documents_mapped):\n",
    "                review_index = 0\n",
    "            \n",
    "            buffer.extend(documents_mapped[review_index][word_index:word_index + span])\n",
    "            \n",
    "            word_index += span\n",
    "        else:\n",
    "            # add next word in review\n",
    "            buffer.append(documents_mapped[review_index][word_index])\n",
    "            word_index += 1\n",
    "            \n",
    "    return batch, labels\n",
    "            \n",
    "batch_size = 500\n",
    "num_skips = 5\n",
    "skip_window = 3\n",
    "test_batch = generate_batch(documents_mapped, batch_size, num_skips, skip_window)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_batch[0].shape[0] == batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embeddings\n",
    "\n",
    "# latent features\n",
    "embedding_size = 50\n",
    "vocabulary_size = len(vocabulary)\n",
    "# init values\n",
    "embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "\n",
    "# initialize weights and biases for word2vect model\n",
    "# each unique word gets a weight per latent feature and a single bias\n",
    "nce_weights = tf.Variable(\n",
    "  tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                      stddev=1.0 / math.sqrt(embedding_size)))\n",
    "nce_biases = tf.Variable(tf.zeros([vocabulary_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for inputs (reviews are read in in batches during training)\n",
    "batch_size = 25\n",
    "\n",
    "train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2941, 2941, 2941, 2941, 2941, 2941, 2941, 2941, 2941, 2941],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch[0][test_batch[0] == test_batch[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size // num_skips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2941, 2941, 2941, 2941, 2941, 1182, 1182, 1182, 1182, 1182, 7367,\n",
       "       7367, 7367, 7367, 7367, 5300, 5300, 5300, 5300, 5300, 8424, 8424,\n",
       "       8424, 8424, 8424, 3486, 3486, 3486, 3486, 3486, 7132, 7132, 7132,\n",
       "       7132, 7132, 2941, 2941, 2941, 2941, 2941, 1182, 1182, 1182, 1182,\n",
       "       1182, 7367, 7367, 7367, 7367, 7367, 5300, 5300, 5300, 5300, 5300,\n",
       "       5625, 5625, 5625, 5625, 5625, 7930, 7930, 7930, 7930, 7930, 6366,\n",
       "       6366, 6366, 6366, 6366, 7564, 7564, 7564, 7564, 7564, 6070, 6070,\n",
       "       6070, 6070, 6070, 1061, 1061, 1061, 1061, 1061, 3768, 3768, 3768,\n",
       "       3768, 3768, 8424, 8424, 8424, 8424, 8424, 3486, 3486, 3486, 3486,\n",
       "       3486, 4139, 4139, 4139, 4139, 4139, 6715, 6715, 6715, 6715, 6715,\n",
       "       7912, 7912, 7912, 7912, 7912, 5841, 5841, 5841, 5841, 5841, 5625,\n",
       "       5625, 5625, 5625, 5625, 3700, 3700, 3700, 3700, 3700, 1335, 1335,\n",
       "       1335, 1335, 1335, 8424, 8424, 8424, 8424, 8424, 9760, 9760, 9760,\n",
       "       9760, 9760, 7672, 7672, 7672, 7672, 7672, 8424, 8424, 8424, 8424,\n",
       "       8424, 8060, 8060, 8060, 8060, 8060, 5564, 5564, 5564, 5564, 5564,\n",
       "       2895, 2895, 2895, 2895, 2895, 8424, 8424, 8424, 8424, 8424, 5352,\n",
       "       5352, 5352, 5352, 5352, 7564, 7564, 7564, 7564, 7564, 3486, 3486,\n",
       "       3486, 3486, 3486, 5953, 5953, 5953, 5953, 5953, 1182, 1182, 1182,\n",
       "       1182, 1182, 5334, 5334, 5334, 5334, 5334, 4927, 4927, 4927, 4927,\n",
       "       4927, 8424, 8424, 8424, 8424, 8424, 1641, 1641, 1641, 1641, 1641,\n",
       "       8578, 8578, 8578, 8578, 8578, 1690, 1690, 1690, 1690, 1690, 2196,\n",
       "       2196, 2196, 2196, 2196, 3709, 3709, 3709, 3709, 3709, 3149, 3149,\n",
       "       3149, 3149, 3149, 8424, 8424, 8424, 8424, 8424, 9891, 9891, 9891,\n",
       "       9891, 9891, 8662, 8662, 8662, 8662, 8662, 5625, 5625, 5625, 5625,\n",
       "       5625, 7930, 7930, 7930, 7930, 7930, 5108, 5108, 5108, 5108, 5108,\n",
       "       9436, 9436, 9436, 9436, 9436, 4737, 4737, 4737, 4737, 4737, 1182,\n",
       "       1182, 1182, 1182, 1182, 7852, 7852, 7852, 7852, 7852, 6621, 6621,\n",
       "       6621, 6621, 6621, 1654, 1654, 1654, 1654, 1654, 8424, 8424, 8424,\n",
       "       8424, 8424, 8327, 8327, 8327, 8327, 8327, 2939, 2939, 2939, 2939,\n",
       "       2939, 3486, 3486, 3486, 3486, 3486, 4016, 4016, 4016, 4016, 4016,\n",
       "       5953, 5953, 5953, 5953, 5953, 1520, 1520, 1520, 1520, 1520, 1690,\n",
       "       1690, 1690, 1690, 1690, 5625, 5625, 5625, 5625, 5625,  587,  587,\n",
       "        587,  587,  587, 1182, 1182, 1182, 1182, 1182, 3486, 3486, 3486,\n",
       "       3486, 3486,  850,  850,  850,  850,  850,  624,  624,  624,  624,\n",
       "        624, 1081, 1081, 1081, 1081, 1081, 7564, 7564, 7564, 7564, 7564,\n",
       "        511,  511,  511,  511,  511, 4629, 4629, 4629, 4629, 4629, 5841,\n",
       "       5841, 5841, 5841, 5841, 8578, 8578, 8578, 8578, 8578, 8138, 8138,\n",
       "       8138, 8138, 8138, 2360, 2360, 2360, 2360, 2360, 1335, 1335, 1335,\n",
       "       1335, 1335, 8424, 8424, 8424, 8424, 8424, 4881, 4881, 4881, 4881,\n",
       "       4881, 2517, 2517, 2517, 2517, 2517, 2166, 2166, 2166, 2166, 2166,\n",
       "       2843, 2843, 2843, 2843, 2843, 2041, 2041, 2041, 2041, 2041, 5841,\n",
       "       5841, 5841, 5841, 5841, 6596, 6596, 6596, 6596, 6596, 1322, 1322,\n",
       "       1322, 1322, 1322, 9706, 9706, 9706, 9706, 9706, 7473, 7473, 7473,\n",
       "       7473, 7473, 3184, 3184, 3184, 3184, 3184, 8628, 8628, 8628, 8628,\n",
       "       8628, 3845, 3845, 3845, 3845, 3845, 8424, 8424, 8424, 8424, 8424,\n",
       "       8273, 8273, 8273, 8273, 8273], dtype=int32)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
